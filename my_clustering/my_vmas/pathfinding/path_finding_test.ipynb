{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents:\n",
      "Agent(state.pos=tensor([[-0.0150,  1.0729]]))\n",
      "Agent(state.pos=tensor([[-1.6461, -1.4719]]))\n",
      "Agent(state.pos=tensor([[-0.7703,  0.5363]]))\n",
      "Agent(state.pos=tensor([[-0.0396,  1.5858]]))\n",
      "\n",
      "Targets:\n",
      "Target(state.pos=tensor([[-0.1775,  0.5292]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-0.6044, -0.3931]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-1.9107, -1.3246]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-0.8244,  0.0741]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[0.7907, 1.2000]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[-1.3559, -0.8709]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[0.7264, 1.6608]]), Target(cost)=30)\n",
      "Target(state.pos=tensor([[-0.4116,  1.4966]]), Target(cost)=30)\n",
      "Target(state.pos=tensor([[-0.3224,  0.2116]]), Target(cost)=30)\n",
      "Target(state.pos=tensor([[ 1.8110, -1.8553]]), Target(cost)=40)\n",
      "Target(state.pos=tensor([[-1.2591, -0.5063]]), Target(cost)=40)\n",
      "Target(state.pos=tensor([[-0.7796,  1.7280]]), Target(cost)=40)\n",
      "\n",
      "FinishedTargets:\n",
      "FinishedTarget(state.pos=tensor([[0.2000, 0.2000]]))\n",
      "FinishedTarget(state.pos=tensor([[ 0.2000, -0.2000]]))\n",
      "FinishedTarget(state.pos=tensor([[-0.2000, -0.2000]]))\n",
      "FinishedTarget(state.pos=tensor([[-0.2000,  0.2000]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 상태를 저장하는 별도의 클래스 정의 (옵션)\n",
    "class State:\n",
    "    def __init__(self, pos):\n",
    "        self.pos = pos\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.pos}\"\n",
    "\n",
    "# Agent 클래스 정의\n",
    "class Agent:\n",
    "    def __init__(self, pos):\n",
    "        self.state = State(pos)  # 객체의 위치는 self.state.pos에 저장\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Agent(state.pos={self.state.pos})\"\n",
    "\n",
    "# Target 클래스 정의\n",
    "class Target:\n",
    "    def __init__(self, pos, cost):\n",
    "        self.state = State(pos)  # 객체의 위치는 self.state.pos에 저장\n",
    "        self.cost = cost\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Target(state.pos={self.state.pos}, Target(cost)={self.cost})\"\n",
    "    \n",
    "class FinishedTarget:\n",
    "    def __init__(self, pos):\n",
    "        self.state = State(pos)  # 객체의 위치를 self.state.pos에 저장\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FinishedTarget(state.pos={self.state.pos})\"\n",
    "\n",
    "\n",
    "\n",
    "# 주어진 위치 텐서 값들을 정의\n",
    "agent_positions = [\n",
    "    torch.tensor([[-0.0150,  1.0729]]),\n",
    "    torch.tensor([[-1.6461, -1.4719]]),\n",
    "    torch.tensor([[-0.7703,  0.5363]]),\n",
    "    torch.tensor([[-0.0396,  1.5858]])\n",
    "]\n",
    "\n",
    "target_positions = [\n",
    "    torch.tensor([[-0.1775,  0.5292]]),\n",
    "    torch.tensor([[-0.6044, -0.3931]]),\n",
    "    torch.tensor([[-1.9107, -1.3246]]),\n",
    "    torch.tensor([[-0.8244,  0.0741]]),\n",
    "    torch.tensor([[ 0.7907,  1.2000]]),\n",
    "    torch.tensor([[-1.3559, -0.8709]]),\n",
    "    torch.tensor([[ 0.7264,  1.6608]]),\n",
    "    torch.tensor([[-0.4116,  1.4966]]),\n",
    "    torch.tensor([[-0.3224,  0.2116]]),\n",
    "    torch.tensor([[ 1.8110, -1.8553]]),\n",
    "    torch.tensor([[-1.2591, -0.5063]]),\n",
    "    torch.tensor([[-0.7796,  1.7280]])\n",
    "]\n",
    "\n",
    "target_cost = [10, 10, 10, 20, 20, 20, 30, 30, 30, 40, 40, 40]\n",
    "\n",
    "# 각 객체 생성\n",
    "agents = [Agent(pos) for pos in agent_positions]\n",
    "targets = []\n",
    "for i in range(12):\n",
    "    target = Target(pos=target_positions[i], cost=target_cost[i])\n",
    "    targets.append(target)\n",
    "    \n",
    "# 주어진 finished_pos 값 (첫번째 값의 중첩 리스트는 제거하고, 모두 Tensor 형식으로 통일)\n",
    "dist = 0.2\n",
    "finished_pos = [\n",
    "    torch.tensor([[dist, dist]]),\n",
    "    torch.tensor([[dist, -dist]]),\n",
    "    torch.tensor([[-dist, -dist]]),\n",
    "    torch.tensor([[-dist, dist]])\n",
    "]\n",
    "\n",
    "# finished_target 객체 4개 생성\n",
    "finished_targets = [FinishedTarget(pos) for pos in finished_pos]\n",
    "\n",
    "\n",
    "\n",
    "# 생성된 객체 출력\n",
    "print(\"Agents:\")\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "\n",
    "print(\"\\nTargets:\")\n",
    "for target in targets:\n",
    "    print(target)\n",
    "print()\n",
    "\n",
    "# 생성된 finished_target 객체 출력\n",
    "print(\"FinishedTargets:\")\n",
    "for ft in finished_targets:\n",
    "    print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Target(state.pos=tensor([[-0.4116,  1.4966]]), Target(cost)=30), Target(state.pos=tensor([[-0.7796,  1.7280]]), Target(cost)=40)], [Target(state.pos=tensor([[0.7907, 1.2000]]), Target(cost)=20), Target(state.pos=tensor([[0.7264, 1.6608]]), Target(cost)=30)], [Target(state.pos=tensor([[-0.1775,  0.5292]]), Target(cost)=10), Target(state.pos=tensor([[-0.6044, -0.3931]]), Target(cost)=10), Target(state.pos=tensor([[-1.9107, -1.3246]]), Target(cost)=10), Target(state.pos=tensor([[-0.8244,  0.0741]]), Target(cost)=20), Target(state.pos=tensor([[-1.3559, -0.8709]]), Target(cost)=20), Target(state.pos=tensor([[-0.3224,  0.2116]]), Target(cost)=30), Target(state.pos=tensor([[-1.2591, -0.5063]]), Target(cost)=40)], [Target(state.pos=tensor([[ 1.8110, -1.8553]]), Target(cost)=40)]]\n",
      "\n",
      "Target(state.pos=tensor([[-0.4116,  1.4966]]), Target(cost)=30)\n",
      "Target(state.pos=tensor([[-0.7796,  1.7280]]), Target(cost)=40)\n",
      "\n",
      "Target(state.pos=tensor([[0.7907, 1.2000]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[0.7264, 1.6608]]), Target(cost)=30)\n",
      "\n",
      "Target(state.pos=tensor([[-0.1775,  0.5292]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-0.6044, -0.3931]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-1.9107, -1.3246]]), Target(cost)=10)\n",
      "Target(state.pos=tensor([[-0.8244,  0.0741]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[-1.3559, -0.8709]]), Target(cost)=20)\n",
      "Target(state.pos=tensor([[-0.3224,  0.2116]]), Target(cost)=30)\n",
      "Target(state.pos=tensor([[-1.2591, -0.5063]]), Target(cost)=40)\n",
      "\n",
      "Target(state.pos=tensor([[ 1.8110, -1.8553]]), Target(cost)=40)\n",
      "\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def targets_clustering(agents, targets, finished_targets, cost_weight=1.0):\n",
    "    \"\"\"\n",
    "    타겟 12개의 위치와 코스트를 이용하여, 탐색 비용(거리 + 코스트 패널티)을 고려한 클러스터링을 수행합니다.\n",
    "    \n",
    "    탐색 비용은 두 타겟 i, j에 대해:\n",
    "       distance(i,j) = ||pos_i - pos_j|| + ((cost_i + cost_j) / 2) * cost_weight\n",
    "    로 정의됩니다.\n",
    "    \n",
    "    이 거리 행렬을 이용하여 AgglomerativeClustering (계층적 군집화)를 수행하고,\n",
    "    결과를 4개의 클러스터(리스트의 리스트)로 반환합니다.\n",
    "    \n",
    "    agents, finished_targets는 이번 클러스터링에서는 사용하지 않음.\n",
    "    \n",
    "    Args:\n",
    "        agents: 사용하지 않음 (함수 시그니처 유지용)\n",
    "        targets: Target 객체들의 리스트. 각 객체는 target.state.pos (torch.Tensor, shape: (1,2))와 target.cost (스칼라)를 가짐.\n",
    "        finished_targets: 사용하지 않음 (함수 시그니처 유지용)\n",
    "        cost_weight (float): 코스트가 거리 비용에 미치는 영향력.\n",
    "    \n",
    "    Returns:\n",
    "        list: 4개의 클러스터(리스트의 리스트). 각 클러스터는 할당된 Target 객체들을 포함.\n",
    "    \"\"\"\n",
    "    n = len(targets)\n",
    "    # 각 타겟의 위치와 코스트를 추출 (위치는 2차원 벡터, 코스트는 스칼라)\n",
    "    positions = [target.state.pos.flatten().cpu().numpy() for target in targets]  # 수정: .cpu() 추가\n",
    "    costs = [target.cost for target in targets]\n",
    "    \n",
    "    # n x n 크기의 거리(탐색 비용) 행렬 계산\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            euclidean = np.linalg.norm(positions[i] - positions[j])\n",
    "            cost_penalty = ((costs[i] + costs[j]) / 2) * cost_weight\n",
    "            d = euclidean + cost_penalty\n",
    "            dist_matrix[i, j] = d\n",
    "            dist_matrix[j, i] = d\n",
    "\n",
    "    # AgglomerativeClustering은 precomputed metric을 사용 (scikit-learn 최신 버전 기준)\n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=4, \n",
    "        metric=\"precomputed\",\n",
    "        linkage=\"average\"\n",
    "    )\n",
    "    labels = clustering.fit_predict(dist_matrix)\n",
    "    \n",
    "    # labels에 따라 타겟들을 클러스터별로 분류\n",
    "    clusters = [[] for _ in range(4)]\n",
    "    for target, label in zip(targets, labels):\n",
    "        clusters[label].append(target)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "clusters = targets_clustering(agents, targets, finished_targets, cost_weight=0.1)\n",
    "score = 0\n",
    "print(clusters)\n",
    "print()\n",
    "for item in clusters:\n",
    "    for temp in item:\n",
    "        print(temp)\n",
    "    print()\n",
    "    \n",
    "    score += len(item)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0:\n",
      "  Target(state.pos=tensor([[0.7264, 1.6608]]), Target(cost)=30)\n",
      "  Target(state.pos=tensor([[0.7907, 1.2000]]), Target(cost)=20)\n",
      "Agent 1:\n",
      "  Target(state.pos=tensor([[-1.9107, -1.3246]]), Target(cost)=10)\n",
      "  Target(state.pos=tensor([[-1.3559, -0.8709]]), Target(cost)=20)\n",
      "  Target(state.pos=tensor([[-1.2591, -0.5063]]), Target(cost)=40)\n",
      "  Target(state.pos=tensor([[-0.6044, -0.3931]]), Target(cost)=10)\n",
      "  Target(state.pos=tensor([[-0.8244,  0.0741]]), Target(cost)=20)\n",
      "  Target(state.pos=tensor([[-0.3224,  0.2116]]), Target(cost)=30)\n",
      "  Target(state.pos=tensor([[-0.1775,  0.5292]]), Target(cost)=10)\n",
      "Agent 2:\n",
      "  Target(state.pos=tensor([[ 1.8110, -1.8553]]), Target(cost)=40)\n",
      "Agent 3:\n",
      "  Target(state.pos=tensor([[-0.4116,  1.4966]]), Target(cost)=30)\n",
      "  Target(state.pos=tensor([[-0.7796,  1.7280]]), Target(cost)=40)\n",
      "Total Cost: 15.416238\n",
      "[[Target(state.pos=tensor([[0.7264, 1.6608]]), Target(cost)=30), Target(state.pos=tensor([[0.7907, 1.2000]]), Target(cost)=20)], [Target(state.pos=tensor([[-1.9107, -1.3246]]), Target(cost)=10), Target(state.pos=tensor([[-1.3559, -0.8709]]), Target(cost)=20), Target(state.pos=tensor([[-1.2591, -0.5063]]), Target(cost)=40), Target(state.pos=tensor([[-0.6044, -0.3931]]), Target(cost)=10), Target(state.pos=tensor([[-0.8244,  0.0741]]), Target(cost)=20), Target(state.pos=tensor([[-0.3224,  0.2116]]), Target(cost)=30), Target(state.pos=tensor([[-0.1775,  0.5292]]), Target(cost)=10)], [Target(state.pos=tensor([[ 1.8110, -1.8553]]), Target(cost)=40)], [Target(state.pos=tensor([[-0.4116,  1.4966]]), Target(cost)=30), Target(state.pos=tensor([[-0.7796,  1.7280]]), Target(cost)=40)]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def solve_open_tsp(points, start, finish):\n",
    "    \"\"\"\n",
    "    주어진 points(2차원 좌표 리스트)에 대해, start에서 시작하여 finish에서 끝나는 open TSP 문제를 \n",
    "    브루트포스로 해결합니다.\n",
    "    \n",
    "    각 경로의 비용은 아래와 같이 계산합니다:\n",
    "       cost = distance(start, first_point) + \n",
    "              Σ(distance(point_i, point_{i+1})) + \n",
    "              distance(last_point, finish)\n",
    "    \n",
    "    Args:\n",
    "        points (list of np.array): 타겟들의 2차원 좌표 리스트.\n",
    "        start (np.array): 시작 좌표.\n",
    "        finish (np.array): 종료 좌표.\n",
    "    \n",
    "    Returns:\n",
    "        best_perm (tuple): points의 인덱스로 구성된 최적 순서.\n",
    "        best_cost (float): 최적 순서에 따른 총 이동 비용.\n",
    "        \n",
    "        만약 points가 빈 리스트라면, start와 finish 사이의 거리를 반환합니다.\n",
    "    \"\"\"\n",
    "    if not points:\n",
    "        return (), np.linalg.norm(start - finish)\n",
    "    \n",
    "    best_cost = float('inf')\n",
    "    best_perm = None\n",
    "    for perm in itertools.permutations(range(len(points))):\n",
    "        cost = np.linalg.norm(start - points[perm[0]])\n",
    "        for i in range(len(perm)-1):\n",
    "            cost += np.linalg.norm(points[perm[i]] - points[perm[i+1]])\n",
    "        cost += np.linalg.norm(points[perm[-1]] - finish)\n",
    "        if cost < best_cost:\n",
    "            best_cost = cost\n",
    "            best_perm = perm\n",
    "    return best_perm, best_cost\n",
    "\n",
    "def open_tsp_assignment(agents, clusters, finished_targets):\n",
    "    \"\"\"\n",
    "    각 에이전트(시작, 도착 위치가 있음)와 클러스터(타겟 그룹)를 매칭시켜 open TSP 경로를 결정합니다.\n",
    "    \n",
    "    처리 과정:\n",
    "      1. 4개의 클러스터(클러스터링 결과)는 순서(label)는 임의로 부여되어 있으므로,\n",
    "         에이전트와 클러스터 간의 할당을 모든 경우(순열)로 고려합니다.\n",
    "      2. 각 에이전트에 대해, 할당된 클러스터의 타겟들을 방문하는 최적의 순서를 open TSP 문제로 해결합니다.\n",
    "         (시작: agent.state.pos, 종료: finished_targets 해당 에이전트의 위치)\n",
    "      3. 모든 에이전트의 open TSP 비용의 합이 최소가 되는 할당 및 방문 순서를 선택합니다.\n",
    "      4. 최종 반환값은 2차원 리스트로, 각 인덱스가 에이전트를 나타내며 내부 리스트에 해당 에이전트가 방문할 타겟 객체들이 순서대로 들어갑니다.\n",
    "         그리고 최적 총 비용(best_total_cost)도 함께 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        agents (list): Agent 객체 리스트. 각 객체는 agent.state.pos (torch.Tensor)를 가짐.\n",
    "        clusters (list): 클러스터링 결과, 4개의 타겟 그룹 (각 그룹은 Target 객체 리스트)\n",
    "        finished_targets (list): FinishedTarget 객체 리스트. 각 객체는 finished_target.state.pos (torch.Tensor)를 가짐.\n",
    "    \n",
    "    Returns:\n",
    "        best_routes_2d (list of list): 각 에이전트별 방문 순서에 따른 타겟 객체들의 2차원 리스트.\n",
    "                                       예) best_routes_2d[agent_idx] = [target_obj1, target_obj2, ...]\n",
    "        best_total_cost (float): 모든 에이전트의 open TSP 비용 합계 (나중에 확인용으로 사용).\n",
    "    \"\"\"\n",
    "    n_agents = len(agents)\n",
    "    best_total_cost = float('inf')\n",
    "    best_assignment = None\n",
    "    best_routes = {}  # 임시 저장: {agent_idx: {'cluster_index': ..., 'route_order': ..., 'cost': ..., 'cluster_targets': ...}}\n",
    "    \n",
    "    # 모든 할당(에이전트와 클러스터의 순열)을 고려 (총 4! 가지)\n",
    "    for perm in itertools.permutations(range(n_agents)):\n",
    "        total_cost = 0.0\n",
    "        routes = {}\n",
    "        for agent_idx, cluster_idx in enumerate(perm):\n",
    "            agent = agents[agent_idx]\n",
    "            start = agent.state.pos.flatten().numpy()\n",
    "            finish = finished_targets[agent_idx].state.pos.flatten().numpy()\n",
    "            \n",
    "            # 할당된 클러스터 내의 타겟들의 좌표 추출\n",
    "            cluster = clusters[cluster_idx]\n",
    "            points = [target.state.pos.flatten().numpy() for target in cluster]\n",
    "            \n",
    "            # open TSP 해결: start → cluster의 타겟 순회 → finish\n",
    "            route_order, cost = solve_open_tsp(points, start, finish)\n",
    "            total_cost += cost\n",
    "            routes[agent_idx] = {\n",
    "                'cluster_index': cluster_idx,\n",
    "                'route_order': route_order,   # cluster 리스트 내에서의 순서 (인덱스 튜플)\n",
    "                'cost': cost,\n",
    "                'cluster_targets': cluster\n",
    "            }\n",
    "        if total_cost < best_total_cost:\n",
    "            best_total_cost = total_cost\n",
    "            best_assignment = perm\n",
    "            best_routes = routes\n",
    "    \n",
    "    # best_routes 딕셔너리를 이용해 2차원 리스트 형태로 각 에이전트별 방문 타겟 객체들을 재배열\n",
    "    best_routes_2d = []\n",
    "    for agent_idx in range(n_agents):\n",
    "        route_info = best_routes[agent_idx]\n",
    "        cluster_targets = route_info['cluster_targets']\n",
    "        # route_order는 cluster_targets 내 인덱스 순서\n",
    "        ordered_targets = [cluster_targets[i] for i in route_info['route_order']]\n",
    "        best_routes_2d.append(ordered_targets)\n",
    "    \n",
    "    return best_routes_2d, best_total_cost\n",
    "\n",
    "# 예시 사용:\n",
    "# agents, clusters, finished_targets 는 앞서 클러스터링 단계와 에이전트, finished_target 생성 단계에서 제공된 객체들입니다.\n",
    "best_routes_2d, best_total_cost = open_tsp_assignment(agents, clusters, finished_targets)\n",
    "\n",
    "# 예시 출력:\n",
    "for agent_idx, route in enumerate(best_routes_2d):\n",
    "    print(f\"Agent {agent_idx}:\")\n",
    "    for target in route:\n",
    "        print(\" \", target)\n",
    "print(\"Total Cost:\", best_total_cost)\n",
    "print(best_routes_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
